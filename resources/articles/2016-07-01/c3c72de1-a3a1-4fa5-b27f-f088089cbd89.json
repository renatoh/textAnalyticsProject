{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "technology/2016/jul/05/tesla-crash-self-driving-car-software-flaws", "type": "article", "sectionId": "technology", "sectionName": "Technology", "webPublicationDate": "2016-07-05T21:44:46Z", "webTitle": "Why self-driving cars aren't safe yet: rain, roadworks and other obstacles", "webUrl": "https://www.theguardian.com/technology/2016/jul/05/tesla-crash-self-driving-car-software-flaws", "apiUrl": "https://content.guardianapis.com/technology/2016/jul/05/tesla-crash-self-driving-car-software-flaws", "fields": {"headline": "Why self-driving cars aren't safe yet: rain, roadworks and other obstacles", "bodyText": "Last week\u2019s fatal crash involving a Tesla Model S offers a startling reminder that driverless technology is still a work in progress. As Tesla\u2019s own blogpost on the \u201ctragic loss\u201d points out, the autopilot technology that was controlling Joshua Brown\u2019s car when it ploughed into a truck is in a \u201cpublic beta phase\u201d. That means the software has been released into the wild to be stress-tested by members of the public so that bugs can be flushed out. It\u2019s the kind of approach we are used to seeing when we gain early access to new email applications or virtual reality headsets. As Apple co-founder Steve Wozniak told the New York Times: \u201cBeta products shouldn\u2019t have such life-and-death consequences\u201d. Until the investigation into the tragic incident concludes, we won\u2019t know whether it was caused by a software glitch or human error \u2013 particularly with reports suggesting the driver may have been watching a Harry Potter DVD. All we know is that \u201cneither autopilot nor the driver\u201d noticed the white side of the tractor trailer against the brightly lit sky \u201cso the brake was not applied\u201d. Tesla\u2019s autopilot uses both cameras and radar to detect and avoid obstacles, so in this case we know there must have been a double failure. The cameras struggled with the glare from the sun, while the radar \u2013 according to Musk \u2013 \u201ctunes out what looks like an overhead road sign to avoid false braking events\u201d. Elon Musk may have taken to aggressively dismissing coverage of the crash on his Twitter account, but there are still significant every day flaws that presents obstacles to wider adoption of self-driving car technology. Sensor fusion When you have multiple sensors giving conflicting information, which one do you defer to? This seemed to be an issue at play in the fatal Tesla crash, where the one sensor that did spot the truck misinterpreted it as a road sign overhead. \u201cThe big question for driverless car makers is: how does the intelligence of the machine know that the radar sensor is the one to believe? That\u2019s the secret sauce,\u201d says Sridhar Lakshmanan, a self-driving car specialist and engineering professor at the University of Michigan-Dearborn. Roadworks When Delphi sent an autonomous car 3,400 miles across the US in April 2015, engineers had to take control of the car only for a 50-mile stretch. The reason? Unpredictable urban conditions with unmarked lanes and heavy roadworks. In other words, an average city commute. Sandbags (and assumptions) One of Google\u2019s self-driving cars collided with a public bus in Mountain View in February as it tried to navigate some sandbags on the street. In attempting to move around the sandbags, the car\u2019s left front struck the side of the bus that was trying to overtake. The car had detected the bus but predicted it would yield, and the test driver behind the wheel also made that assumption. \u201cUnfortunately, all these assumptions led us to the same spot in the lane at the same time. This type of misunderstanding happens between human drivers on the road every day,\u201d said Google of the incident. Weather Adverse weather conditions create visibility problems for both people and the sensors that power driverless technology. Rain can reduce the range and accuracy of laser-based Lidar sensors, obscure the vision of on-board cameras and create confusing reflections and glare. In a bid to improve the performance of driverless technology in soggy conditions, Google has started testing its cars on public roads near Seattle, where regular rain is guaranteed. Hacking As cars become more hi-tech they become more vulnerable to hacking. With driverless vehicles, the extra computers, internet connectivity and sensors increase the possible vulnerabilities. In a proof-of-concept attack, security researcher Jonathan Petit showed that lidar can be easily fooled into detecting a non-existent obstacle using a handheld laser pointer, which can force the car to slow down, stop or swerve. Humans Just as humans are at fault in more than 90% of car accidents, so too can they be the weakest link in semi-autonomous vehicles \u2013 particularly when a functionality labelled as \u201cautopilot\u201d encourages users to place their trust in the machine. \u201cMaybe these intermediate levels [of automation] are not a viable consumer product,\u201d says Richard Wallace, the director of the Transportation Systems Analysis group within the Center for Automotive Research. \u201cThey go a little too far in encouraging drivers to check out and yet they aren\u2019t ready to take control.\u201d And other humans It\u2019s not just the humans inside cars with self-driving technology, but those in other vehicles that need to be vigilant. Accident rates involving driverless cars are twice as high as for regular cars, according to a study by the University of Michigan\u2019s Transportation Research Institute which looked at data from Google, Delphi and Audi. However the driverless cars weren\u2019t at fault \u2013 they are typically hit from behind by inattentive or aggressive humans unaccustomed to self-driving motorists being such sticklers for the road rules. Google has started to programme its cars differently to behave in more familiar, human ways, such as inching forward at a four-way stop to indicate they will be moving next. But it\u2019s this collision where the biggest challenges for technology firms lie, encouraging adoption of rapidly developing new technology for a population that is quirky, unpredictable and, in turn, both sceptical and overtrusting."}, "isHosted": false, "pillarId": "pillar/news", "pillarName": "News"}}}