{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "lifeandstyle/2019/nov/07/you-sound-worried-would-you-let-an-ai-change-the-tone-of-your-emails", "type": "article", "sectionId": "lifeandstyle", "sectionName": "Life and style", "webPublicationDate": "2019-11-06T17:00:42Z", "webTitle": "'You sound worried': would you let an AI change the tone of your emails?", "webUrl": "https://www.theguardian.com/lifeandstyle/2019/nov/07/you-sound-worried-would-you-let-an-ai-change-the-tone-of-your-emails", "apiUrl": "https://content.guardianapis.com/lifeandstyle/2019/nov/07/you-sound-worried-would-you-let-an-ai-change-the-tone-of-your-emails", "fields": {"headline": "'You sound worried': would you let an AI change the tone of your emails?", "bodyText": "On the first episode of the final season of HBO comedy series Silicon Valley, tech startup engineer Bertram Gilfoyle lets an AI version of himself take over his instant messaging duties. \u201cDo you need the real me for this conversation?\u201d he asks his colleague. It may sound extreme, but the existence of spellcheckers predates the personal computer by a decade. Since 1992, grammar checking has also come as standard in word processors. For the better part of a generation, we\u2019ve been OK with robots watching and correcting our language, occasional run-ins with Clippy aside. Now predictive text software on our phones monitors how we write every day; and Gmail\u2019s Smart Compose suggests one-click canned responses to every email. Silicon Valley\u2019s AI mimicked its character\u2019s misanthropy, but grammar-correcting software Grammarly had a more polite vision in mind when it launched a new \u201ctone detector\u201d feature. They asked their users: \u201cHave you ever pressed send on an email and realised it may have sounded a bit too aggressive?\u201d You install the artificial intelligence-powered plugin on to your web browser, where it scans your emails and grades them as \u201cconfident\u201d, \u201coptimistic\u201d, \u201cworried\u201d or \u201csceptical\u201d \u2013 it claims to identify 40 tones. Much like a spellchecker, it will read through your text and then make suggestions at the bottom of your screen, or when you hover your mouse over a grumpy red underline. It feels neat and familiar, but the software raises a broader question than the one it asks its users: to what standard are our interactions being steered? \u201cGrammarly can tell you how your message is likely to sound to someone reading it,\u201d co-founder and product manager Alex Shevchenko tells Guardian Australia. It will also provide suggestions to spice up vocabulary it deems ineffective or bland, suggesting, \u201cthrilled\u201d over \u201cvery happy\u201d; and that \u201cu\u201d instead of \u201cyou\u201d is inappropriately casual. The phrase, \u201cI think we should be able to solve this issue for you\u201d will flash red, before it changes to \u201cwe can solve this issue for you\u201d \u2013 it sounds more \u201cconfident\u201d according to the handshake emoji at the bottom of the screen. The tone detector, which works across American, British, Australian and Canadian English, was designed by a team of linguists and software engineers. It learns from its users, too, so if the majority votes a word fits one \u201ctone\u201d, then alternative forms of communication lose value and the most popular tone choice is normalised. But technology is not a magical orb that exists beyond our reality; every dataset, rule and machine-learning algorithm is guided by its human creators and users and the biases they carry. \u201cThere is a dominant tone,\u201d Deborah Raji, a robotics engineer and tech fellow at the AI Now Institute in New York, says of Grammarly\u2019s detector. \u201cWhatever they\u2019re using to train their models \u2026 automatically kind of supersedes any other dialect or smaller group that speaks differently, and that dialect ends up being branded as the wrong thing.\u201d These technologies therefore risk reinforcing the idea that less common methods of communication are less valid. Grammarly does not collect gender or age information from its users and therefore doesn\u2019t take these into account when providing feedback, which means that everyone\u2019s words are edited equally. Shevchenko says the software is more about giving agency and empowering effective communication. \u201cWe understand that the contexts in which people communicate involve biases and assumptions, and it\u2019s our hope that the tone detector offers support in navigating such complexities.\u201d Other programs do take the identity of the sender into account. Non-AI Google Chrome plugin Just Not Sorry, created by New York-based software consultancy Def Method, was designed to help women erase unnecessary qualifiers from their emails. It highlights hedging words like \u201cI just think\u201d or \u201cwe could\u201d to help users sound more assured. Rachel Adams, an AI and international human rights law research specialist at the Human Sciences Research Council, explains that modifying phatic speech (the kind aimed at establishing a social relationship instead of discussing ideas \u2013 like asking, \u201chow are you?\u201d) tells users that the dominant, masculine-corporate speech is preferable. If they want to sound confident, they need to follow suit. \u201cAI needs to be very narrow in its focus but think very carefully and broadly about what the social impacts of its technologies are, and to try to develop technologies that are much more inclusive in the way that they operate. It should allow for multiple ways of expression,\u201d Adams says. \u201cIt\u2019s like saying, is there is one single truth that exists that we can all agree to? And there\u2019s not.\u201d Grammarly and Just Not Sorry also can\u2019t account for how the receiver reads the message. Some people speak cautiously because they have adapted to their immediate social expectations. Software might be able to tell you what\u2019s normative, but it cannot tell that you\u2019ve intentionally phrased an email delicately because it\u2019s 12.30pm on a Thursday and you know your boss will be hangry when they read it. That requires social nous even the cleverest algorithm can\u2019t process. While a tone detector can be a helpful bulwark against a hastily worded message, or a useful tool for those who speak English as a second language, the outgoing benefits of these technologies are not equal for every user. As Raji explains, \u201cIt doesn\u2019t account for these kinds of specific contexts, because it actually does matter who\u2019s sending it. Not everyone can sound the same.\u201d"}, "isHosted": false, "pillarId": "pillar/lifestyle", "pillarName": "Lifestyle"}}}