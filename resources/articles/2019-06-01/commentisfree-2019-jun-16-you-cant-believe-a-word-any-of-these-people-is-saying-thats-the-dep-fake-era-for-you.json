{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "commentisfree/2019/jun/16/you-cant-believe-a-word-any-of-these-people-is-saying-thats-the-dep-fake-era-for-you", "type": "article", "sectionId": "commentisfree", "sectionName": "Opinion", "webPublicationDate": "2019-06-16T05:00:40Z", "webTitle": "You can\u2019t believe a word any of these people is saying \u2013 that\u2019s the \u2018deep fake\u2019 era for you | Jamie Bartlett", "webUrl": "https://www.theguardian.com/commentisfree/2019/jun/16/you-cant-believe-a-word-any-of-these-people-is-saying-thats-the-dep-fake-era-for-you", "apiUrl": "https://content.guardianapis.com/commentisfree/2019/jun/16/you-cant-believe-a-word-any-of-these-people-is-saying-thats-the-dep-fake-era-for-you", "fields": {"headline": "You can\u2019t believe a word any of these people is saying \u2013 that\u2019s the \u2018deep fake\u2019 era for you", "bodyText": "We are entering an age in which you can no longer trust your ears or eyes. Bots, trolls and fake news merchants have demolished the idea that you can believe what you read online. But audio and video always felt like truth\u2019s life raft, offering an accurate portrayal of reality we could cling to. Not for much longer. Forget post-truth, this is the era of post-reality, where \u201cdeep fake\u201d software will allow anyone to create believable video footage of anyone saying anything. Last week, some artists published a convincing deep fake of Facebook chief, Mark Zuckerberg, saying: \u201cThe more you express yourself, the more we own you.\u201d A couple of months ago, Barack Obama was out there telling viewers to \u201cstay woke, bitches\u201d, while before that the young anti-gun activist Emma Gonz\u00e1lez was faked into tearing up the US constitution, to the misplaced fury of some Republicans. There are hundreds of these videos circulating, with more every day. The US House intelligence committee, worried by the possible national security risks, met to discuss this last week. In some ways, deep fakes aren\u2019t all that new: the selective editing and clipping of real footage to create a falsehood, a \u201cshallow fake\u201d, you could say, is already the staple of conspiracy theorists and even the odd respectable news outlet. And large-scale political fakery is as old as the hills: your grandparents might remember the \u201cZinoviev letter\u201d, a 1924 forgery published by the Daily Mail that was purportedly from the Soviet Comintern, asking the British Communist party to engage in sedition. The difference now is that it is cheaper, easier, quicker and done far better. Deep fakes still aren\u2019t perfect, but digital technologies improve rapidly. They were originally designed to improve movie production, but within five years what was once the million-dollar CGI preserve of Hollywood studios will be a free app on your phone. It\u2019s easy to imagine what happens then. Fake but perfect videos will circulate of Donald Trump saying he\u2019s secretly a member of the Ku Klux Klan or that George Soros is funding an anti-democratic coup. You will see the announcement of a nuclear strike \u2013 leaked on Twitter. A supposedly \u201cprivate recording\u201d where a candidate admits to colluding with a foreign government will fly around the world faster and farther than any press-released rebuttal. No doubt a future Cambridge Analytica will be paid to make sure these videos reach certain key swing voters the day before an election. The possibilities are especially dangerous in countries with existing ethnic or religious tensions and less experience in dealing with digital literacy. In India, simple faked images and videos of alleged child kidnappings have led to lynchings, while in Gabon rumours about a deep fake video of President Ali Bongo created a political crisis. The problem won\u2019t be restricted to the rich and famous \u2013 you too might be the subject of a deep fake. There are chatrooms in seedy digital corners where developers will make fake sex tapes of anyone you ask them to \u2013 an ex, an annoying colleague? \u2013 for around $20. (Like many pioneering technologies, deep fakes are being popularised via pornography.) There is already a counter-movement: academic conferences, the US military and Facebook researchers are all involved in an arms race, trying to build fraud-spotting tech. (Literally in some cases: one technique involves looking for unusual arm gesticulation.) This is vital work \u2013 perhaps the most important technological task of the next 10 years \u2013 but it\u2019s only part of the answer. Deep fakes\u2019 greatest strength is not technological, but our willingness to believe and click \u201cshare\u201d for any old nonsense so long as it fits in with our pre-existing views about the world. You might assume that deep fakes mean everyone will believe everything they see, but the real risk to democracy is the opposite: no one will believe anything at all. If everything is potentially fakable, everything can be dismissed as lie. A leading politician caught lying on camera? It\u2019s a deep fake! At the first hint of a crisis, \u201cpreviously unseen footage\u201d will emerge, while old speeches will be edited with expedient content inserted. The main effect of deep fakes in our politics therefore will not be to spread lies, but, rather, confusion and apathy. Authoritarians here and abroad must be thrilled. Over the past few years, they have developed a new technique of censorship by distraction, smothering truths under a torrent of meaningless rubbish. They will soon be able to do this automatically, pumping out millions or even billions of pieces of content to keep everyone suitably confused. As the political scientist Hannah Arendt wrote in the 1950s, the ideal subject of an authoritarian regime is not a committed Nazi or Bolshevik, but someone for whom \u201cthe distinction between fact and fiction, true and false, no longer exists\u201d, because they are far more malleable. The health of democracies all over the world will depend on finding ways to re-establish the veracity of video and audio content \u2013 and temper our own willingness to believe or disbelieve according to our own prejudices. And if we can\u2019t? In the face of constant and endless deep fakes and deep denials, the only rational response from the citizen will be extreme cynicism and apathy about the very idea of truth itself. They will conclude that nothing is to be trusted except her own gut instinct and existing political loyalties. In other words, the age of deep fakes might even succeed in making today\u2019s visceral and divided politics look like a golden age of reasonableness. \u2022 Jamie Bartlett is the author of The People vs Tech"}, "isHosted": false, "pillarId": "pillar/opinion", "pillarName": "Opinion"}}}