{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "politics/2001/sep/10/polls.socialsciences", "type": "article", "sectionId": "politics", "sectionName": "Politics", "webPublicationDate": "2001-09-09T23:59:42Z", "webTitle": "Analysis: Faulty psephology", "webUrl": "https://www.theguardian.com/politics/2001/sep/10/polls.socialsciences", "apiUrl": "https://content.guardianapis.com/politics/2001/sep/10/polls.socialsciences", "fields": {"headline": "Faulty psephology", "bodyText": "Later this week at the annual Political Studies Association conference devoted to elections and polling, the June 7 result will be the focus - as will our performance as pollsters. On the Friday following election day, Gallup, Mori and NOP said they had confounded their critics with \"the best result since 1987\". Yet the polling industry has little to crow about. The table compares the final polls with the outcome of each of the last eight elections. The closest prediction this year, by ICM for the Guardian, was 0.6% adrift; the most inaccurate estimate was askew by 2.8% in Labour's favour. The June election fits the pattern of previous contests in that the polls have overstated Labour's advantage. If the problem were sampling error we should be able to observe a range of predictions around the correct result. Instead, we see errors mostly in the same direction. That indicates not error but bias. Final polls suggested that Labour would win by 15%, but over the course of the campaign polls had suggested Labour's advantage was 17%, double what the party actually achieved. Indeed, three polls put Labour ahead by 25% or more. The exaggeration was not new. Except for a brief spell before Black Wednesday in 1992 and a couple of months during the petrol crisis last year, most polls suggested Labour would do better in elections than it did. The only hope for the pollsters is to blame voters for not acting as they say they intended. The worry must be that it is their methods that are at fault. One excuse is that there was a late swing away from Labour that mainly benefited the Liberal Democrats. Another is that substantial numbers of traditional Labour supporters made late decisions not to turn out. We checked. On election day ICM re-contacted 1,533 people who had previously been asked how they intended to vote in polls preceding June 7. The results show that Labour lost a maximum of 1% over the course of the last few days because of \"late swing\" and failure of supporters to turn out. In other words, these factors explain only a small fraction of the error in the estimates made by most pollsters. Opinion poll companies hope that by getting the demographic profile of their samples to match the whole population, their surveys will give an accurate picture of voting intentions. Trouble is, the days when the toffs voted Tory and the flat-capped working classes supported Labour have long gone. A demographically representative poll is no longer necessarily politically balanced. Added to which, response rates are low and falling. Some people are difficult to interview and some do not want to disclose their intentions. At present, however, pollsters simply replace \"refusers\" with others who share the same demographic profile. This is to ignore the possibility that it might be easier to find Labour voters willing to say they will support a party they perceive is popular than to find Conservatives willing to admit backing a less fashionable alternative. You would have thought that most people could remember how they voted in the last election. Yet, according to one poll conducted three weeks after the 2001 election only 26% remembered having voted Conservative (7% too low) and 48% said they had voted Labour (6% too high). On the face of it, such polls contain too many Labour voters and too few Tories. So why not use past voting behaviour to ensure the polls are demographically and politically representative? Some say you cannot trust past votes because some forget how they voted and others align past votes to present intentions. Of course, pollsters have to make allowances for faulty recall, but if the pollsters were to weight people's recollections so they get closer to the outcome last time they would get more accurate predictions. Over the course of this year's campaign, Gallup, Mori and NOP suggested the Lib Dems would obtain 14% of the popular vote while their final polls predicted they would get 17%, two points short of their actual score. That makes it seem like the Lib Dems had a sparkling campaign. But there is another explanation. In the penultimate week of the election Mori suddenly changed its methodology and showed its respondents a list of candidates and parties fighting the election in their constituencies. From an average score of 13% for the Lib Dems before the change, their final two polls had them on 17% and 19%. ICM had been prompting throughout with the names of the parties. The ICM average score for the Lib Dems over the whole campaign was 17% and 19% on the final Guardian poll - exactly what they achieved. People need to be reminded of all the alternatives if some are not to select from the most obvious options. So are people or pollsters to blame for the fact that most overstated Labour's advantage in the run-up to the 2001 election? The evidence suggests the pollsters, both because of a tendency for Conservatives to be under-represented in poll samples and because unprompted voting questions fail to remind people of the Liberal Democrat alternative. \u0095 Nick Sparrow is managing director of ICM Research nick.sparrow@icmresearch. co.uk"}, "isHosted": false, "pillarId": "pillar/news", "pillarName": "News"}}}