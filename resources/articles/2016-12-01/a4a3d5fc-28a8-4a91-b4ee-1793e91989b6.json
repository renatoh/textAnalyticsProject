{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "sustainable-business/2016/dec/02/the-moral-challenge-of-military-robots-arises-when-we-delegate-fighting-wars", "type": "article", "sectionId": "sustainable-business", "sectionName": "Guardian Sustainable Business", "webPublicationDate": "2016-12-01T22:42:51Z", "webTitle": "The moral challenge of military robots arises when we delegate fighting wars", "webUrl": "https://www.theguardian.com/sustainable-business/2016/dec/02/the-moral-challenge-of-military-robots-arises-when-we-delegate-fighting-wars", "apiUrl": "https://content.guardianapis.com/sustainable-business/2016/dec/02/the-moral-challenge-of-military-robots-arises-when-we-delegate-fighting-wars", "fields": {"headline": "The moral challenge of military robots arises when we delegate fighting wars", "bodyText": "Long before undergoing any proper study of war, I remember believing I had the problem sorted. In primary school, I remember remarking to friends that we could spare the lives of so many soldiers and civilians if leaders could simply agree what was being contested and have a chess match to determine the victor. The loser, I proposed, would then concede and the conflict would be resolved with no need for bloodshed. Reading Machiavelli later, I realised the obvious flaw in my solution: to put all your fortune into anything less than your entire army is often risky, dumb and irresponsible. All the same, the idea of a kind of war with minimal casualties remains appealing \u2013 and has throughout history. From so-called champions fighting in single combat \u2013 for instance, Siamese King Naresuan and Burmese Prince Mingyi Swa in the 16th century \u2013 to international agreements like the Hague and Geneva conventions, which restrict warfare to particular forms, we\u2019ve constantly tried to manage the potential harms of war. Today, the quest for \u201crisk-free\u201d warfare seems to have reached its zenith in the increasing presence of robots on the battlefield. From the armed drones we read so much about \u2013 which allow targeted strikes to be administered by remote-controlled aeroplanes \u2013 to bomb disposal bots, the advantages of these techno troopers are pretty obvious. Not being human, these bots are expendable, albeit pricy. This means they can be deployed in contexts where it would be imprudent or irresponsible to send human combatants. This is exactly the argument the US president, Barack Obama, deployed in defence of his drone policy, including CIA drone strikes in Pakistan, Yemen and Somalia, and estimates of civilian casualties varying from less than 100 to over 800. Obama said it was \u201cnot possible for America to simply deploy a team of special forces to capture every terrorist. Even when such an approach may be possible, there are places where it would pose profound risks to our troops and local civilians.\u201d As the capacities of military robots expand from semi-autonomous machines to potentially fully autonomous, Terminator-style combatants, we should expect to see these arguments used with even greater force. The future we anticipate for military robots is a fully capable war fighter able to be deployed in place of a human soldier. Not only will this spare a human being the risks of combat, it might help protect civilians as well. With adrenaline pumping in the heat of combat, it might be hard for a soldier to make a split-second judgement on whether movement on his flank is an enemy trying to get a clear shot or a civilian seeking cover. A robot faces fewer obstacles to clear decision-making and might more regularly be able to make the right call, sparing not only civilian lives, but the moral trauma of having taken a life. It\u2019s here \u2013 in the avoidance of the moral problems associated with killing \u2013 that the great moral challenge of military robots arises. In essence, delegating the task of fighting war to robots means alleviating humans like us from the responsibility of making life-and-death decisions \u2013 including the potential psychological costs that responsibility entails. Yet, as with any area of technological development, we need to consider whether war and killing are activities that are appropriate to outsource to machines. In his play, Les Justes, Albert Camus pre-empts this question in his depiction of a group of revolutionaries plotting the assassination of Russian Grand Duke Sergei Alexandrovich. The abiding point of the play is that moral justification for killing relies to some extent on one\u2019s own willingness to die. Refusing to assume the risk of your own death is to miss the moral seriousness of killing; it means forfeiting any ethical defence for what you\u2019ve done, in essence turning killing into murder. Camus\u2019 claims might go a bit too far. Firstly, many who are willing to die have no right to kill \u2013 terrorists, most obviously. Secondly, it\u2019s hard to argue that someone trying to defend justice and do what\u2019s right needs to be willing to die in order to do so: we wouldn\u2019t think a police officer unwilling to give their life was unworthy of the role. However, in the ambiguity of modern warfare it can be unclear precisely where justice lies. Because of this, having humans who recognise the moral seriousness of killing involved might be critically important. The conscientious reflection of those whose hands will actually do the killing serves as another safeguard against the potentially reckless administration of force by political leaders. Earlier in the US presidential campaign, Donald Trump promised to bring back waterboarding and other forms of torture. In response, the former CIA director Michael Hayden suggested rightly that troops would likely refuse to obey his commands. If risk-free, automated war became a possibility, one of the crucial safeguards against war crimes \u2013 the conscience, honour and personal ethics of military personnel, and what philosopher and psychologist William James described as a \u201cpure piece of perfection\u201d \u2013 might be lost. Regardless of their complexity, mechanised combatants will never be able to feel the moral implications of killing and the ethical reflection it sparks. While it is often less than this, in its purest form, war is one of the most raw expressions of our commitment to treat some subjects with moral seriousness. It reveals a truth which is easy to overlook in the innocuousness of the day to day: there are things for which a people are \u2013 and should be \u2013 willing to die. Because war isn\u2019t anything so banal as a chess game. It cannot be conducted in a vacuum and though we should aim to protect innocent people from the direct consequences of conflict by seeking alternatives to war, when it does inevitably occur, we cannot \u2013 and should not \u2013 be fully inoculated from the ethical consequences. When we send our sons, daughters, fathers, sisters and friends off to war, each of us feels the moral significance of the act. We use it to hold leaders to account, question the necessity of the conflict and express gratitude for what our armed forces are defending. It\u2019s true, we might feel the costs of war less if it were fought by machines \u2013 in many ways that would be a good thing. But \u201cnot feeling\u201d has a cost of its own: not to be emotionally and intellectually compelled to understand and avoid the horror of war also seems horrific in its own way."}, "isHosted": false}}}