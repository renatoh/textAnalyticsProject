{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "commentisfree/2019/dec/09/facebook-moderator-worst-of-humanity-valued", "type": "article", "sectionId": "commentisfree", "sectionName": "Opinion", "webPublicationDate": "2019-12-09T08:00:03Z", "webTitle": "As a Facebook moderator I saw the worst of humanity. We need to be valued | Chris Gray", "webUrl": "https://www.theguardian.com/commentisfree/2019/dec/09/facebook-moderator-worst-of-humanity-valued", "apiUrl": "https://content.guardianapis.com/commentisfree/2019/dec/09/facebook-moderator-worst-of-humanity-valued", "fields": {"headline": "As a Facebook moderator I saw the worst of humanity. We need to be valued", "bodyText": "You may have shrugged when you heard that some Facebook staff are suing the company over working conditions. But welcome to my world \u2013 content moderation \u2013 where we deal with the worst of humanity so you don\u2019t have to. Naked migrants are being tortured with molten metal in Libya; Facebook\u2019s quality assurance (QA) department is challenging whether that baby in Myanmar is dead; Dave and Doreen are using its report function as a weapon again. All their tedious posts end up on a screen in front of us, punctuated by atrocities, porn and distasteful jokes. I used to be one of the tens of thousands of skilled analysts deciding whether your post is hateful, exposing something hateful, misinformed, innocent, satirical, sarcastic or just plain stupid. With billions of people on Facebook it only takes a tiny percentage to post \u201cinappropriate\u201d stuff, which often gets shared and re-posted endlessly, before you need an army of moderators \u2013 the specialists who keep your newsfeed clean, so you can continue to look at the ads Facebook makes billions out of. We respond if some maniac livestreams their killing rampage, your ex objects to your ice-bucket challenge because they can see your nipples, a sexual predator is stalking someone you love, or a depressed teenager is asking her friends whether she should live or die. Moderators make hundreds of decisions about these things every day. It\u2019s skilled, measured work. It needs to be done by smart, well-adjusted people with a strong moral compass who can balance the freedoms of the individual against the rights of society. We\u2019re poorly paid and under constant pressure. We can\u2019t pause to reflect on the dead baby we saw, because we\u2019re so worried about whether we made the right decision and can keep QA happy. It\u2019s not just the gore and suffering, it\u2019s the insidious drip-drip-drip of half-truths and emotional arguments that make extremists start to make sense, and those racist memes look really funny. We don\u2019t sleep much, we\u2019re irritable, can\u2019t focus, have problems in our marriages, not that we can talk about it. We sign non-disclosure agreements, the Facebook Omert\u00e0, so the people closest to us have no idea we may have witnessed a murder tonight. Four times. We may have had to watch it over and over, under the benevolent gaze of the huge smiley-face emojis that cover the walls, because it was a complicated case and QA were watching us, too. We wake up in the night after replaying it in our dreams, worried about the mistake we might have made. Is it good to have emotionally disturbed people policing the internet? Maybe one day artificial intelligence will be able to spot nuance and context enough to differentiate between satire and hate, find a way to manage Dave and Doreen, and make judgment calls about when a victim is actually dead, but it\u2019s not going to happen any time soon. Until then, you\u2019re relying on a secret army in the shadows to protect your kids from perverts and extreme content. They\u2019re not allowed to talk about their conditions or even identify themselves. Facebook chief Mark Zuckerberg makes proud public announcements about how many moderators there are, then dismisses their complaints as \u201ca little overdramatic\u201d. Facebook says it provides \u201cwellness\u201d, which meant invitations to finger painting and yoga, but try taking time off to take care of yourself when you have targets to meet and your boss is agitating because there\u2019s a backlog in the child sexual abuse images queue. Someone has to take care of the innocents, it\u2019s our job, but we can\u2019t face it any more. So here we are, filing writs in the high court of Ireland \u2013 not simply seeking compensation but looking for respect. We need our part in your healthy internet to be recognised and valued, which means quantifying the harm done and paying the cost of making things right. Thanks to the tireless work of campaigners and lawyers in the UK and Ireland, content moderators are now being heard. Since going public I have heard countless stories of trauma and illness from people who were previously afraid to speak out. Nobody wants to be anonymous, nobody wants to be disposable. We took this job to make a difference. Now we understand we\u2019re fighting Facebook as much as we\u2019re fighting extreme content. \u2022 Chris Gray is a former Facebook moderator"}, "isHosted": false, "pillarId": "pillar/opinion", "pillarName": "Opinion"}}}