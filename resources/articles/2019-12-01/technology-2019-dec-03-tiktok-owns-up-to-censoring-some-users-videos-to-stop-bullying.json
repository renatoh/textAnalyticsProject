{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "technology/2019/dec/03/tiktok-owns-up-to-censoring-some-users-videos-to-stop-bullying", "type": "article", "sectionId": "technology", "sectionName": "Technology", "webPublicationDate": "2019-12-03T14:16:58Z", "webTitle": "TikTok owns up to censoring some users' videos to stop bullying", "webUrl": "https://www.theguardian.com/technology/2019/dec/03/tiktok-owns-up-to-censoring-some-users-videos-to-stop-bullying", "apiUrl": "https://content.guardianapis.com/technology/2019/dec/03/tiktok-owns-up-to-censoring-some-users-videos-to-stop-bullying", "fields": {"headline": "TikTok owns up to censoring some users' videos to stop bullying", "bodyText": "TikTok has admitted censoring posts by users it identified as disabled, fat or LGBTQ+ as part of a misguided effort to cut down on bullying on the platform. According to a report from the German site NetzPolitik.org, the video-sharing site artificially limited the reach of users who it thought would be vulnerable to bullying if their videos reached a wide audience. The suppression took different forms: for some users, it meant that their videos were not shown outside their native country; for others, it kept the content from TikTok\u2019s most popular algorithmic feed, the public \u201cFor You\u201d page, after they had hit a certain view count. Generally, it was applied to specific videos, but some high-profile users were singled out and given the unasked-for protection. The automatic restrictions were applied to users who were \u201csusceptible to bullying or harassment based on their physical or mental condition\u201d, according to documents obtained by NetzPolitik.org, including \u201cfacial disfigurement, autism, Down syndrome, [or] disabled people or people with some facial problems\u201d. Other users were put on the restriction list \u2013 categorised as \u201cAuto R\u201d \u2013 manually, based on their high risk of bullying. A \u201cstriking number\u201d of these \u201cspecial users\u201d, NetzPolitik.org reports, \u201cshow a rainbow flag in their biographies or describe themselves as lesbian, gay or non-binary \u2026 The list also includes users who are simply fat and self-confident.\u201d TikTok confirmed the substance of the reporting, telling the publication that the rules were a stopgap solution to bullying on the platform, and were \u201cnever intended to be a long-term solution\u201d. In a follow-up statement, TikTok said: \u201cEarly on, in response to an increase in bullying on the app, we implemented a blunt and temporary policy. While the intention was good, the approach was wrong and we have long since changed the earlier policy in favour of more nuanced anti-bullying policies and in-app protections.\u201d According to Netzpolitik.org, the rules were in place as recently as September. The leaks are the latest to demonstrate how TikTok takes a much firmer hand with content moderation on its site than its Silicon Valley-native competitors. The firm, which is owned by the Chinese unicorn Bytedance, had previously instructed moderators to follow a series of guidelines that saw them hiding videos that went against Beijing orthodoxy: content that supported Taiwan\u2019s continued independence, or referred to the killings in Tiananmen Square, was hidden from sight. Those rules, TikTok says, were changed in May."}, "isHosted": false, "pillarId": "pillar/news", "pillarName": "News"}}}