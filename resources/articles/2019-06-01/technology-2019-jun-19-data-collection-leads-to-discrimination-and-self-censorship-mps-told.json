{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "technology/2019/jun/19/data-collection-leads-to-discrimination-and-self-censorship-mps-told", "type": "article", "sectionId": "technology", "sectionName": "Technology", "webPublicationDate": "2019-06-19T14:33:17Z", "webTitle": "Data collection leads to discrimination and self-censorship, MPs told", "webUrl": "https://www.theguardian.com/technology/2019/jun/19/data-collection-leads-to-discrimination-and-self-censorship-mps-told", "apiUrl": "https://content.guardianapis.com/technology/2019/jun/19/data-collection-leads-to-discrimination-and-self-censorship-mps-told", "fields": {"headline": "Data collection leads to discrimination and self-censorship, MPs told", "bodyText": "Widespread data collection practices lead to self-censorship and discrimination even though most users are not fully aware of how much their privacy is being infringed, a parliamentary committee has been warned. On Wednesday, the human rights committee, beginning its inquiry into the right to privacy and the digital revolution, published evidence from privacy and data protection organisations including the Information Commissioner\u2019s Office, Liberty and Privacy International. Taken as a whole, the submitted evidence paints a picture of a nation that does not understand what happens to its data, cannot give meaningful consent to how it is used, and ends up self-censoring for fear of being watched. Liberty said in its submission: \u201cThat private companies exploit our data for commercial purposes is now a normalised part of our everyday existence. The data collected can reveal and manipulate our deepest and most sensitive thoughts and feelings \u2013 including our political views. \u201cThe normalisation of these processes also threatens our freedom of expression and association by making it clear that we are being watched. Studies have shown that we are likely to censor what we post on social media or what we look up online when we are aware they are being surveilled.\u201d The ICO warned that the modern data economy runs the risk of embedding discrimination in the fabric of society. When a company uses \u201clookalike audiences\u201d, for instance, it uses algorithms and analytics to identify those individuals most like to be similar in characteristics to those it wishes to target. \u201cThere is growing evidence that inherent biases are built into algorithms resulting in the risk of discriminatory outcomes, which runs contrary to the principle of fairness. Additionally, the principles of consent, transparency and accountability are all engaged by this activity,\u201d the ICO said. The Law Society of Scotland warned that, while the EU\u2019s general data protection regulation (GDPR) goes a long way to protect citizens from abuses of personal data, \u201cconsumers may not fully understand the potential impact that certain uses of their data might have\u201d. It suggested education about use of data consent might be important. \u201cRelevant issues to consider in this context include: the (increasing) complexity of algorithms; extent to which personal data is shared with other organisations; and the extent to which personal data is collected, commoditised and used for personalised marketing. \u201cWhile some actors uphold the principles of transparency and offer real choice to consent, we are aware that others are still not meeting the basic requirements of the UK data protection legislation and do not offer consumers real choice,\u201d it said. Privacy International warned that the focus should not just be on data that was collected, since many companies accurately inferred far more personal information than they collected: \u201cCompanies routinely derive data from other data, such as determining how often someone calls their mother to calculate their credit-worthiness. \u201cAs a result, potentially sensitive data can be inferred from seemingly mundane data, such as future health risks. Combined data can reveal people\u2019s political and religious views; socioeconomic status; finances; spending habits; physical and mental health; relationships status; sexual preferences; family planning; internet browsing activities; and more.\u201d Privacy International added: \u201cCombining data may expose patterns of behaviour people themselves are not aware of and highly sensitive information that they did not knowingly provide.\u201d The inquiry will begin taking oral evidence over the coming months, before reporting on whether Britain needs new safeguards to regulate the collection, use, tracking, retention and disclosure of personal data by private companies."}, "isHosted": false, "pillarId": "pillar/news", "pillarName": "News"}}}