{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "us-news/2020/feb/20/mike-bloomberg-debate-video-facebook-twitter-instagram", "type": "article", "sectionId": "us-news", "sectionName": "US news", "webPublicationDate": "2020-02-20T22:05:52Z", "webTitle": "Bloomberg debate video sparks new concern over social media disinformation", "webUrl": "https://www.theguardian.com/us-news/2020/feb/20/mike-bloomberg-debate-video-facebook-twitter-instagram", "apiUrl": "https://content.guardianapis.com/us-news/2020/feb/20/mike-bloomberg-debate-video-facebook-twitter-instagram", "fields": {"headline": "Bloomberg debate video sparks new concern over social media disinformation", "bodyText": "A heavily edited video of Mike Bloomberg\u2019s performance at Wednesday\u2019s democratic debate in Nevada has prompted fresh questions about disinformation policies on social media platforms. The video posted by the Bloomberg campaign to Instagram on Thursday paints a flattering portrait of the former New York mayor\u2019s widely panned debate performance, showing Bloomberg\u2019s Democratic rivals responding with an extended silence after Bloomberg says he is the \u201conly one here, I think, that\u2019s ever started a business\u201d. While the former New York mayor did make that statement at the debate, the response was edited to make it look as though the other candidates had no response. A spokesman from Twitter told the Guardian that the Bloomberg post would probably fall under a new policy that will place warning labels next to significantly altered content starting on 5 March. The feature will show a warning to people before they like or retweet a post that Twitter has determined to be manipulated. The company will also reduce the visibility of misleading tweets and provide additional explanations with them. The video does not, however, violate Facebook \u201cmanipulated media\u201d policies and will stay on Instagram, which Facebook owns. A spokesman, Andy Stone, tweeted on Thursday that \u201cthis video does not violate our manipulated media policy\u201d. Facebook\u2019s policy prohibits content that has been edited in ways that are \u201cnot apparent to the average person\u201d and would lead viewers into believing someone in the video said words they did not actually say. It also bans videos that are \u201cthe product of artificial intelligence or machine learning that merges, replaces, or superimposes content into a video in a manner that makes it appear authentic\u201d. The Bloomberg video raised questions reminiscent of those that followed the controversy over a video of House speaker Nancy Pelosi, which was edited to appear as though she had ripped up a speech by Donald Trump while he was honoring a Tuskegee airman and other attendees. In that case, Facebook and Twitter rejected Pelosi\u2019s request to remove the video. These cases again raise questions about what content should be taken down and who should make those decisions, said Claire Wardle, the co-founder of the Harvard not-for-profit group First Draft, which researches misinformation. \u201cAs we\u2019ve been saying for a long time, it becomes very dangerous to think about taking down this type of content, as the internet and television have been and continue to be full of this type of political content globally,\u201d Wardle said. \u201cIf you take this down, you have to take down a lot of content, and the lines are going to be incredibly blurred.\u201d The video was not meant to be viewed as real, said Galia Slayen, press secretary for Bloomberg\u2019s campaign. \u201cIt\u2019s tongue-in-cheek,\u201d she said. \u201cThere were obviously no crickets on the debate stage.\u201d Facebook also responded on Thursday to questions surrounding Bloomberg\u2019s \u201cdeputy digital organizing\u201d team, which pays $2,500 per month to campaigners responsible for promoting Bloomberg to their friends via text and on social media. Nathaniel Gleicher, the head of security policy at Facebook, said via Twitter that this would not constitute coordinated inauthentic behavior, which he said was defined in its community standards as an effort that has \u201ca central reliance on a network of fake accounts\u201d. \u201cBased on the descriptions, that doesn\u2019t sound like what\u2019s happening here,\u201d the tweet said. He added that social media companies needed \u201cclearer guidance from regulators\u201d as political efforts create a gray area in terms of what qualifies as an organized attack."}, "isHosted": false, "pillarId": "pillar/news", "pillarName": "News"}}}