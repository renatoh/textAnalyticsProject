{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "commentisfree/2019/jun/24/deepfakes-facebook-silicon-valley-responsibility", "type": "article", "sectionId": "commentisfree", "sectionName": "Opinion", "webPublicationDate": "2019-06-24T06:00:08Z", "webTitle": "Deepfakes aren't a tech problem. They're a power problem | Oscar Schwartz", "webUrl": "https://www.theguardian.com/commentisfree/2019/jun/24/deepfakes-facebook-silicon-valley-responsibility", "apiUrl": "https://content.guardianapis.com/commentisfree/2019/jun/24/deepfakes-facebook-silicon-valley-responsibility", "fields": {"headline": "Deepfakes aren't a tech problem. They're a power problem", "bodyText": "In the lead-up to the 2016 election, very few predicted the degree to which online misinformation would disrupt the democratic process. Now, as we edge closer to 2020, there is a heightened sense of vigilance around new threats to truth in our already fragile information ecosystem. At the top of the list of concerns is no longer Russian bots, but deepfakes, the artifical intelligence-manipulated media that can make people appear to do or say things that they never did or said. The threat is being taken so seriously that last Thursday, the House intelligence committee held Congress\u2019s first hearing on the subject. In his opening remarks, Representative Adam Schiff, the committee chairman, talked of society being \u201con the cusp of a technological revolution\u201d that will qualitatively transform how fake news is made. He spoke of \u201cadvances in AI\u201d that will make it possible to compromise election campaigns. He made repeated mention of how better algorithms and data will make it extremely difficult to verify the veracity of images, videos, audio or text. In essence, he framed the problem of doctored media as a new threat caused by sophisticated emerging technologies. Not that Schiff\u2019s alone. The broader discourse around fake content has become increasingly focused on AI-generated content, where cutting-edge machine learning techniques are used to create uncanny copies of people\u2019s faces, voices and writing styles. But as technologically impressive as these new techniques are, I worry that focusing on the \u201cstate of the art\u201d is a distraction from a deeper problem. To understand why, consider the most high-profile example of manipulated media to spread online to date: the doctored video of the House speaker, Nancy Pelosi, made to seem as if she was drunkenly slurring her speech. Far from being created by a technically savvy operator misappropriating the fruits of a \u201ctechnological revolution\u201d, it was made using rudimentary editing techniques by a sports blogger and avid pro-Trumper from the Bronx named Shawn Brooks. The reason this fake video spread so far and wide was not because it was technologically advanced, or even particularly visually compelling, but because of the cynical nature of social media. When a platform\u2019s business model is to maximize engagement time in order to sell ad revenue, divisive, shocking and conspiratorial content gets pushed to the top of the feed. Like other trolls, Brooks\u2019s most salient skill was understanding and exploiting these dynamics. Indeed, the Pelosi video demonstrated just how symbiotic and mutually beneficial the fake news-platform relationship has become. Facebook refused to take down the altered video, noting that its content policy does not require a post to be true. (Facebook did \u201creduce\u201d the video\u2019s distribution in the news feed, in an attempt at harm minimization.) The reality is that divisive content is, from a financial perspective, a win for social media platforms. As long as that logic underpins our online lives, cynical media manipulators will continue to exploit it to spread social discord, with or without machine learning. And herein lies the problem: by formulating deepfakes as a technological problem, we allow social media platforms to promote technological solutions to those problems \u2013 cleverly distracting the public from the idea that there may be more fundamental problems with powerful Silicon Valley tech platforms. We have seen this before. When Congress interrogated Mark Zuckerberg last year about Facebook\u2019s privacy problems and involvement in spreading fake news, instead of reflecting on structural issues at the company, Zuckerberg repeatedly assured Congress that technological solutions that would fix everything were just over the horizon. Zuckerberg mentioned AI more than 30 times. Underpinning all of this is what Evgeny Morozov has called \u201ctechnological solutionism\u201d: an ideology endemic to Silicon Valley that reframes complex social issues as \u201cneatly defined problems with definite, computable solutions \u2026 if only the right algorithms are in place!\u201d This highly formal, systematic, yet socially myopic mindset is so pervasive within the tech industry that it has become a sort of meme. How do we solve wealth inequality? Blockchain. How do we solve political polarization? AI. How do we solve climate change? A blockchain powered by AI. This constant appeal to a near-future of perfectly streamlined technological solutions distracts and deflects from the grim realities we presently face. While Zuckerberg promised better AI for content moderation in front of Congress last year, reports have since emerged that much content moderation still relies on humans, who are subjected to highly traumatic content and terrible working conditions. By talking incessantly about AI-powered content moderation, the company diverts attention away from this real human suffering. The \u201csolutionist\u201d ideology has also influenced the discourse around how to deal with doctored media. The solutions being proposed are often technological in nature, from \u201cdigital watermarks\u201d to new machine learning forensic techniques. To be sure, there are many experts who are doing important security research to make the detection of fake media easier in the future. This is important and worthwhile. But on its own, it is unclear that this would help fix the deep-seated social problem of truth decay and polarization that social media platforms have played a major role in fostering. The biggest problem with technological solutionism is that it can be used as a smokescreen for deep structural problems in the technology industry, as well as a strategy for stymieing precisely the type of political interventions that need to happen to curtail the singular power that these companies have in controlling how we access information. If we continue to frame deepfakes as a technological problem instead of something rotten at the core of the attention economy, we leave ourselves just as vulnerable in 2020 to misinformation as we were in 2016. Oscar Schwartz is a freelance writer and researcher based in New York"}, "isHosted": false, "pillarId": "pillar/opinion", "pillarName": "Opinion"}}}