{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "technology/2015/oct/20/campaign-to-stop-killer-robots-warning-united-nations", "type": "article", "sectionId": "technology", "sectionName": "Technology", "webPublicationDate": "2015-10-20T22:07:40Z", "webTitle": "Campaign to Stop Killer Robots warns UN of threat 'a few years away'", "webUrl": "https://www.theguardian.com/technology/2015/oct/20/campaign-to-stop-killer-robots-warning-united-nations", "apiUrl": "https://content.guardianapis.com/technology/2015/oct/20/campaign-to-stop-killer-robots-warning-united-nations", "fields": {"headline": "Campaign to Stop Killer Robots warns UN of threat 'a few years away'", "bodyText": "Experts in artificial intelligence, lawyers and activists organized by the Campaign to Stop Killer Robots gathered at the United Nations on Tuesday to warn against a growing reliance on cheap drones and \u201cstupid AI\u201d that can be unpredictable in the real world. \u201cTerminator always comes up,\u201d Toby Walsh, a professor of artificial intelligence at the University of New South Wales, told reporters on Tuesday, referring to the sci-fi cyborg on a mission to wipe out mankind. \u201cBut it\u2019s not really Terminator that we\u2019re worried about at the moment. I think that Terminator is perhaps 50 or so years away.\u201d But there are concerning technologies \u201conly a few years, at best, away\u201d, Walsh said, and with semi-autonomous systems, such as drones, \u201cit would take very little to remove the human from that loop and replace them with a computer\u201d. Walsh and other members of the campaign painted a dire picture of uninhibited artificial intelligence taking root on battlefields and national borders. Unlike those needed for nuclear weapons, they said, the resources to create \u201ckiller robots\u201d will only become cheaper and more available over time. With an online-bought drone, a smartphone and the right software, anyone could create \u201ca little killer robot\u201d, Walsh added. Given the growing availability of robotics \u2013 and the already advanced state of artificial intelligence in the US and UK \u2013 the experts suggested that \u201ckiller robots\u201d may end up having more in common with AK-47s than nuclear bombs. \u201cYou\u2019re going to see them being used in domestic policing, border patrol, riot control, not just armed conflict,\u201d Steve Goose, director of Human Rights Watch\u2019s arms division, told the Guardian. \u201cThe physical platforms already exist. It\u2019s not science fiction, it\u2019s a completely new way of fighting that revolutionizes all of this.\u201d \u201cIf we don\u2019t [create rules], we will end up in an arms race,\u201d Walsh said, \u201cand the endpoint of that arms race is going to be a very undesirable place.\u201d Peter Asaro, a professor at the New School in New York, noted that without a human in control, machines fail to take in the unpredictable variables and context of war: \u201cwhat\u2019s the context, what\u2019s the situation, is the use of force appropriate in this context and this target, and you can automate it but can you automate it well, and who\u2019s responsible when it doesn\u2019t operate correctly\u201d. \u201cThis will seduce us into warfare,\u201d Walsh said. \u201cIt will be too easy, we\u2019ll think that we can fight these wars cleanly, and as we have seen I mentioned with the drone papers, that is a deception because we actually aren\u2019t able to make that kind of technical distinctions between combatant and civilian.\u201d Even with a human ostensibly at the helm, semi-autonomous AI make devastating mistakes, he observed. In the first Gulf war, Patriot missiles struck American and British aircraft, and recently leaked documents about the US drone program revealed a large number of assassinations performed without confirmation of who was killed in strikes. \u201cFrom a technical perspective, if you replace that human with a robot, you\u2019re going to see even more mistakes,\u201d Walsh said. He later told the Guardian that although artificial intelligence in controlled environments \u2013 a factory, a lab \u2013 can work quite well, \u201cour stupid AI today is not as amazing as the human brain\u201d in the unpredictable real world, much less the battlefield. Ian Kerr, a professor of ethics and law at the University of Ottawa, compared the decision to give artificial intelligence the ability to choose targets and kill to \u201ca kind of Russian roulette\u201d, saying it would \u201ccross a moral line that we\u2019ve never crossed before\u201d. Campaign organizers insisted they were not scaremongering and defended the \u201ckiller robot\u201d moniker, saying that the dangers are real and the phrase served them well in the staid world of diplomats and committees. Goose said that Afghanistan and Pakistan \u2013 where hundreds of people, most of them civilians, have been killed in drone strikes in the past decade \u2013 have been particularly vocal supporters of the three-year effort. The US, UK, Israel and South Korea have kept comparatively quiet on the issue; each country has advanced AI programs and ranks among the top spenders on their militaries. The US and UK have policies on military AI, but the activists, who want the UN to formalize talks on \u201cmeaningful human control\u201d, said that both countries\u2019 rules were too ambiguous. Richard Moyes, a managing partner at the UK non-profit Article 36, said although the country has promised there will always be \u201chuman control\u201d, it has not elaborated at all on whether that means a direct operator, a supervisor, simply someone who has activated the AI, or something else entirely. Similarly, the Pentagon policy always requires an \u201cappropriate\u201d level of human control; a spokesperson did not immediately respond to a request for elaboration. And although in 2012 the Pentagon adopted a 10-year plan not to use fully autonomous AI, the measure allows senior officials to overrule it and does not affect research and development. At the UN, the US and Israel have maintained they want \u201cto keep the option open\u201d, Goose said, and Russia and China have quietly watched talks while developing their own programs. \u201cNobody\u2019s \u2019fessing up,\u201d he said. Should the UN formalize talks on 13 November, Goose said he expected an organized opposition to form. He expected, at minimum, that no country would block the renewal of informal talks, and said he hopes for results sooner rather than later. \u201cIf we wait, the technological developments are going to overtake the diplomacy quite quickly,\u201d Goose said."}, "isHosted": false, "pillarId": "pillar/news", "pillarName": "News"}}}