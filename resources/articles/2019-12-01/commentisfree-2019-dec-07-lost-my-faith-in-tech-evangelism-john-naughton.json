{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "commentisfree/2019/dec/07/lost-my-faith-in-tech-evangelism-john-naughton", "type": "article", "sectionId": "commentisfree", "sectionName": "Opinion", "webPublicationDate": "2019-12-07T16:00:14Z", "webTitle": "Sorry, but I\u2019ve lost my faith in tech evangelism", "webUrl": "https://www.theguardian.com/commentisfree/2019/dec/07/lost-my-faith-in-tech-evangelism-john-naughton", "apiUrl": "https://content.guardianapis.com/commentisfree/2019/dec/07/lost-my-faith-in-tech-evangelism-john-naughton", "fields": {"headline": "Sorry, but I\u2019ve lost my faith in tech evangelism", "bodyText": "For my sins, I get invited to give a few public lectures every year. Mostly, the topic on which I\u2019m asked to speak is the implications for democracy of digital technology as it has been exploited by a number of giant US corporations. My general argument is that those implications are not good, and I try to explain why I think this is the case. When I\u2019ve finished, there is usually some polite applause before the Q&amp;A begins. And always one particular question comes up. \u201cWhy are you so pessimistic?\u201d The interesting thing about that is the way it reveals as much about the questioner as it does about the lecturer. All I have done in my talk, after all, is to lay out the grounds for concern about what networked technology is doing to our democracies. Mostly, my audiences recognise those grounds as genuine \u2013 indeed as things about which they themselves have been fretting. So if someone regards a critical examination of these issues as \u201cpessimistic\u201d then it suggests that they have subconsciously imbibed the positive narrative of tech evangelism. An ideology is what determines how you think even when you don\u2019t know you\u2019re thinking. Tech evangelism is an example. And one of the functions of an ideology is to stop us asking awkward questions. Last week Vice News carried another horrifying story about the dark underbelly of social media. A number of Facebook moderators \u2013 those who spot and delete unspeakable content uploaded to the platform \u2013 are suing the company and one of its subcontractors in an Irish court, saying they suffered \u201cpsychological trauma\u201d as a result of poor working conditions and a lack of proper training to prepare them for viewing some of the most horrific content seen anywhere online. \u201cMy first day on the job,\u201d one of them, Sean Burke, reported, \u201cI witnessed someone being beaten to death with a plank of wood with nails in it.\u201d A few days later he \u201cstarted seeing actual child porn\u201d. Facebook employs thousands of people like Burke worldwide, generally using subcontractors. All of the evidence we have is that the work is psychologically damaging and often traumatic. The soothing tech narrative is that Facebook is spending all this money to ensure that our social-media feeds are clean and unperturbing. So it\u2019s an example of corporate social responsibility. The question that is never asked is, why does Facebook allow anybody to post anything they choose \u2013 no matter how grotesque \u2013 on its platforms, when it has total control of those platforms? You know the answer: it involves growth and revenues, and traumatisation of employees is just an unfortunate byproduct of its core business. They\u2019re collateral damage. Or take machine learning, the tech obsession du jour. Of late, engineers have discovered that \u201cbias\u201d is a big problem with that technology. Actually, it\u2019s just the latest manifestation of GIGO \u2013 garbage in, garbage out \u2013 except now it\u2019s BIBO. And there\u2019s a great deal of sanctimonious huffing and puffing in the industry about it, accompanied by trumpeted determination to \u201cfix\u201d it. The trouble is that, as Julia Powles and Helen Nissenbaum pointed out in a recent scorching paper, \u201caddressing bias as a computational problem obscures its root causes. Bias is a social problem, and seeking to solve it within the logic of automation is always going to be inadequate.\u201d But this idea \u2013 that bias is a problem for which there is no technological fix \u2013 is anathema to the tech industry, because it threatens to undermine the deterministic narrative that AI will be everywhere Real Soon Now and the rest of us will just have to get used to it. Worse still (for the tech companies), it might give someone the idea that maybe some kinds of tech should actually be banned because it\u2019s societally harmful. Take facial recognition technology, for example. We already know that it is poor at recognising members of some ethnic groups and researchers are trying to make it more inclusive. But they still implicitly accept that the technology is acceptable. That tacit acceptance is actually buying into the tech-deterministic narrative, though. The question we should be asking \u2013 as the legal scholar Frank Pasquale says \u2013 is whether some of these technologies should be outlawed, or at least licensed for socially productive uses, like, say, radioactive isotopes are for medical purposes. And as regards some of the really dangerous applications of this stuff \u2013 for example face-classifying AI, which is already being explored (and, it seems, deployed in China as a way of inferring sexual orientation, tendencies toward crime, and so on just from images of faces \u2013 shouldn\u2019t we be asking whether this kind of research should be allowed at all? And if anyone regards that as a pessimistic thought, then can I respectfully suggest that maybe they haven\u2019t been paying attention? What I\u2019ve been reading Listen up, libertarians Capitalism needs the state more than the state needs it \u2013 a terrific essay on Aeon by a great economist, Dani Rodrik. It should be required reading in Silicon Valley. His defects are manifest Big tech\u2019s big defector: the title of an interesting New Yorker profile of Roger McNamee, an early investor in Facebook who eventually saw the light, and is now repenting. More haste, less speed Speed reading is for skimmers, slow reading is for scholars, according to David Handel on Medium."}, "isHosted": false, "pillarId": "pillar/opinion", "pillarName": "Opinion"}}}