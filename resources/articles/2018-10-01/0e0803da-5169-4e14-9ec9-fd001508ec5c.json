{"response": {"status": "ok", "userTier": "developer", "total": 1, "content": {"id": "commentisfree/2018/oct/28/regulate-ai-new-laws-code-of-ethics-technology-power", "type": "article", "sectionId": "commentisfree", "sectionName": "Opinion", "webPublicationDate": "2018-10-28T20:58:39Z", "webTitle": "To regulate AI we need new laws, not just a code of ethics | Paul Chadwick", "webUrl": "https://www.theguardian.com/commentisfree/2018/oct/28/regulate-ai-new-laws-code-of-ethics-technology-power", "apiUrl": "https://content.guardianapis.com/commentisfree/2018/oct/28/regulate-ai-new-laws-code-of-ethics-technology-power", "fields": {"headline": "To regulate AI we need new laws, not just a code of ethics", "bodyText": "On giant screens in the European parliament building in Brussels last week, the face of Mark Zuckerberg looked down on the world\u2019s data protection and privacy commissioners assembled there for their annual conference. What he said was cautious and rather bland, but the imagery was potent: a young Big Brother issuing a tailored message to those who administer the laws of many lands. Zuckerberg did not take questions \u2013 a Facebook executive in the chamber did, after Zuckerberg faded from the screens into the green and sunny background of his distant locale. An actual dialogue with the controller of Facebook might have been illuminating. For example, does Facebook anticipate, as others speculate, that the internet will split into two, or three \u2013 the US internet, the China internet and the EU internet? Unlike generalist legislators, data protection and privacy commissioners are among the public\u2019s best equipped representatives for a meaningful public discussion with Zuckerberg. He is among a tiny group of decision-makers who are shaping a world in which human and artificial intelligence combine to collect and use the personal information of billions of people. In their modest specialism, the commissioners are like barometers of the weather ahead for our digital age. For a sense of Facebook\u2019s possible future EU operating environment, Zuckerberg should read the Royal Society\u2019s new publication about the ethical and legal challenges of governing artificial intelligence. One contribution is by a senior European commission official, Paul Nemitz, principal adviser, one of the architects of the EU\u2019s far-reaching General Data Protection Regulation, which took effect in May this year. Nemitz makes clear the views are his own and not necessarily those of the European commission, but the big tech companies might reasonably see his article, entitled \u201cConstitutional democracy and technology in the age of artificial intelligence\u201d, as a declaration of intent. \u201cWe need a new culture of technology and business development for the age of AI which we call \u2018rule of law, democracy and human rights by design\u2019,\u201d Nemitz writes. These core ideas should be baked into AI, because we are entering \u201ca world in which technologies like AI become all pervasive and are actually incorporating and executing the rules according to which we live in large part\u201d. To Nemitz, \u201cthe absence of such framing for the internet economy has already led to a widespread culture of disregard of the law and put democracy in danger, the Facebook Cambridge Analytica scandal being only the latest wake-up call\u201d. Nemitz identifies four bases of digital power which create and then reinforce its unhealthy concentration in too few hands: lots of money, which means influence; control of \u201cinfrastructures of public discourse\u201d; collection of personal data and profiling of people; and domination of investment in AI, most of it a \u201cblack box\u201d not open to public scrutiny. The key question is which of the challenges of AI \u201ccan be safely and with good conscience left to ethics\u201d and which need law. Nemitz sees much that needs law. In an argument both biting and sophisticated, Nemitz sketches a regulatory framework for AI that will seem to some like the GDPR on steroids. Among several large claims, Nemitz argues that \u201cnot regulating these all pervasive and often decisive technologies by law would effectively amount to the end of democracy. Democracy cannot abdicate, and in particular not in times when it is under pressure from populists and dictatorships.\u201d Overall, his case is tied to well established legal principles. For instance: AI that makes decisions that affect individuals should give intelligible reasons; when a machine engages a human in political discourse, the machine should be required by law to disclose that it is a machine; AI that applies rules must conform to the same tests that are used to decide whether laws themselves are legitimate, such as consistency with fundamental rights, due process and proportionality. To Nemitz, these are ways AI can earn the trust needed for broad acceptance in society. An important debate is happening. It is essential that the big tech companies engage in meaningful dialogue, and cease giving the impression that they see interactions with public policymakers mainly within a public relations framework. Some progress has been made over the past year, but more is required, and faster. We are all in this transformative era together. Paul Chadwick is the Guardian readers\u2019 editor"}, "isHosted": false, "pillarId": "pillar/opinion", "pillarName": "Opinion"}}}